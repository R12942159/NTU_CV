{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from cyvlfeat.sift.dsift import dsift\n",
    "from cyvlfeat.kmeans import kmeans\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office',\n",
    "       'Industrial', 'Suburb', 'InsideCity', 'TallBuilding', 'Street',\n",
    "       'Highway', 'OpenCountry', 'Coast', 'Mountain', 'Forest']\n",
    "\n",
    "CAT2ID = {v: k for k, v in enumerate(CAT)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/r12942159/NTU_CV/Hw2/hw2_data/p1_data/train/Bedroom/image_0001.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "tiny_2D = cv2.resize(img, (16, 16), interpolation=cv2.INTER_AREA)\n",
    "tiny_1D = tiny_2D.flatten().astype(np.float32)\n",
    "\n",
    "mean = np.mean(tiny_1D)\n",
    "tiny_1D -= mean\n",
    "\n",
    "norm = np.linalg.norm(tiny_1D)\n",
    "tiny_1D /= (norm + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsift_step = 4\n",
    "vocab_size=100\n",
    "batch_size = 243\n",
    "features = []\n",
    "\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "frames, descriptors = dsift(\n",
    "    img, step=[dsift_step, dsift_step], fast=True)\n",
    "\n",
    "for i in range(descriptors.shape[0]):\n",
    "    features.append(descriptors[i])\n",
    "\n",
    "num_batches = len(features) // batch_size + (1 if len(features) % batch_size != 0 else 0)\n",
    "batches_features = np.array_split(features, num_batches)\n",
    "\n",
    "# Perform k-means clustering on each subset of features\n",
    "vocab = np.empty((0, batches_features[0].shape[1]), np.float32)\n",
    "for batch in batches_features:\n",
    "    batch_vocab, _ = kmeans(batch.astype(np.float32), vocab_size)[:2]\n",
    "    vocab = np.vstack((vocab, batch_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feats = []\n",
    "dsift_step = 4\n",
    "num_samples = 1000\n",
    "\n",
    "img = np.asarray(Image.open(path), dtype='float32')\n",
    "frames, descriptors = dsift(\n",
    "    img, step=[dsift_step, dsift_step], fast=True\n",
    ")\n",
    "\n",
    "if len(descriptors) > num_samples:\n",
    "    idx = np.random.choice(\n",
    "        len(descriptors), size=num_samples, replace=False)\n",
    "    descriptors = descriptors[idx]\n",
    "\n",
    "dist = cdist(vocab, descriptors, metric='euclidean')\n",
    "idx = np.argmin(dist, axis=0)\n",
    "hist, _ = np.histogram(idx, bins=len(vocab))\n",
    "hist_norm = [float(i)/sum(hist) for i in hist]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_Hw2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
